{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet18\n",
        "from torch.nn.functional import normalize\n",
        "import time\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "s--kXgUKfQsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"El dispositivo actual es: {device}\")"
      ],
      "metadata": {
        "id": "t4taDM5e40Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Especifica el nombre del archivo ZIP cargado\n",
        "zip_file = \"images.zip\"\n",
        "\n",
        "# Define el directorio de extracción\n",
        "output_dir = \"/content/images\"\n",
        "\n",
        "# Crea el directorio si no existe\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Descomprimir el archivo\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(output_dir)\n",
        "\n",
        "print(f\"Archivo descomprimido en {output_dir}\")"
      ],
      "metadata": {
        "id": "Zvu19v6I424t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir = \"/content/images\"\n",
        "reference_embeddings = {}"
      ],
      "metadata": {
        "id": "rwmByqi_4971"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
      ],
      "metadata": {
        "id": "vb4Y-laA5GKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(image):\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        embedding = model(image).squeeze(0)\n",
        "    return normalize(embedding, p=2, dim=0).cpu().numpy()"
      ],
      "metadata": {
        "id": "HaD8D80m5MYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "lG8lxsd35S3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet18(weights='IMAGENET1K_V1')\n",
        "model.fc = torch.nn.Identity()\n",
        "model = model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wUuFukNa5WWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attendance_log = []"
      ],
      "metadata": {
        "id": "elBf3u9p6BDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for person_dir in os.listdir(input_dir):\n",
        "    person_path = os.path.join(input_dir, person_dir)\n",
        "    if os.path.isdir(person_path):\n",
        "        for filename in os.listdir(person_path):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                image = cv2.imread(os.path.join(person_path, filename))\n",
        "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "                faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
        "                if len(faces) > 0:\n",
        "                    x, y, w, h = faces[0]\n",
        "                    face = image[y:y + h, x:x + w]\n",
        "                    embedding = get_embedding(face)\n",
        "                    reference_embeddings[person_dir] = embedding"
      ],
      "metadata": {
        "id": "JGYaq7Vs5CKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def js_to_image(js_reply):\n",
        "    image_bytes = b64decode(js_reply.split(',')[1])\n",
        "    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "    img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "    return img"
      ],
      "metadata": {
        "id": "F3YJs4QU532g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def take_photo(quality=0.8):\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(quality) {\n",
        "            const div = document.createElement('div');\n",
        "            const capture = document.createElement('button');\n",
        "            capture.textContent = 'Fotito';\n",
        "            div.appendChild(capture);\n",
        "\n",
        "            const video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "            document.body.appendChild(div);\n",
        "            div.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "            await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            div.remove();\n",
        "            return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "    ''')\n",
        "    display(js)\n",
        "\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    img = js_to_image(data)\n",
        "\n",
        "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f'photo_{timestamp}.jpg'\n",
        "    cv2.imwrite(filename, img)\n",
        "\n",
        "    return filename"
      ],
      "metadata": {
        "id": "RtklinPS5rhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recognize_and_log():\n",
        "    filename = take_photo()\n",
        "    image = cv2.imread(filename)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
        "    local_tz = pytz.timezone('America/Lima')\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        face = image[y:y + h, x:x + w]\n",
        "        embedding = get_embedding(face)\n",
        "\n",
        "        min_distance = float(\"inf\")\n",
        "        recognized_name = \"Desconocido\"\n",
        "        for name, ref_embedding in reference_embeddings.items():\n",
        "            distance = np.linalg.norm(embedding - ref_embedding)\n",
        "            if distance < min_distance and distance < 0.6:\n",
        "                min_distance = distance\n",
        "                recognized_name = name\n",
        "                local_now = datetime.now(local_tz).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "        if recognized_name != \"Desconocido\":\n",
        "            # Registrar información de asistencia\n",
        "            attendance_log.append({\n",
        "                \"Nombre\": recognized_name,\n",
        "                \"Fecha de entrada\": local_now,\n",
        "                \"Imagen\": filename\n",
        "            })\n",
        "            print(f\"Reconocido: {recognized_name}\")\n",
        "\n",
        "            # Dibujar un rectángulo alrededor del rostro reconocido\n",
        "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "            cv2.putText(image, recognized_name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "        else:\n",
        "            print(\"Rostro no reconocido.\")\n",
        "            # Dibujar un rectángulo en rojo para rostros no reconocidos\n",
        "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
        "            cv2.putText(image, \"Desconocido\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
        "\n",
        "    # Mostrar la imagen con las anotaciones utilizando cv2_imshow\n",
        "    cv2_imshow(image)"
      ],
      "metadata": {
        "id": "s4LgpoWX5iPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def automated_recognition():\n",
        "    while True:\n",
        "        recognize_and_log()\n",
        "        print(\"Captura realizada. Esperando 10 segundos para la siguiente.\")\n",
        "        time.sleep(10)  # Espera 10 segundos\n",
        "        if input(\"¿Deseas continuar? (s/n): \").lower() != 's':\n",
        "            break\n"
      ],
      "metadata": {
        "id": "A8PD8vay5mj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "automated_recognition()"
      ],
      "metadata": {
        "id": "smnvlLtZ5oo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(attendance_log)\n",
        "df.to_csv(\"attendance_log.csv\", index=False)\n",
        "print(\"Registro de asistencia guardado en 'attendance_log.csv'\")"
      ],
      "metadata": {
        "id": "mI4fAEskAYKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"attendance_log.csv\")"
      ],
      "metadata": {
        "id": "8qOzz8izAaPP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}